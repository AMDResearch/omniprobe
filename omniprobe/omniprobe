#!/usr/bin/env python3

import argparse
import os
import sys
import io
import selectors
import shutil
import glob
import subprocess
import logging
from pathlib import Path

sys.stdout.reconfigure(line_buffering=True)

#LOGDUR_INSTRUMENTED
#LOGDUR_KERNEL_CACHE
#HSA_TOOLS_LIB
#TRITON_LOGGER_LEVEL=3
#TRITON_HIP_LLD_PATH=${ROCM_HOME}/llvm/bin/ld.lld
#TRITON_ALWAYS_COMPILE=1
#TRITON_DISABLE_LINE_INFO=0
#LLVM_PASS_PLUGIN=[location of plugin.so]

def console_log(*argv, indent_level=0):
    indent = ""
    if indent_level >= 1:
        indent = " " * 3 * indent_level + "|-> "  # spaces per indent level

    if len(argv) > 1:
        logging.info(indent + f"[{argv[0]}] {argv[1]}")
        logging.info(indent + f"[{argv[0]}] {argv[1]}")
    else:
        logging.info(indent + f"{argv[0]}")


def console_debug(*argv):
    if len(argv) > 1:
        logging.debug(f"[{argv[0]}] {argv[1]}")
    else:
        logging.debug(f"{argv[0]}")


def console_warning(*argv):
    if len(argv) > 1:
        for msg in argv:
            if len(msg) > 0:
                logging.info(f"[{msg}]")
        logging.warning(f"[{argv[0]}] {argv[1]}")
    elif len(argv[0]) > 0:
        logging.warning(f"{argv[0]}")



def capture_subprocess_output(subprocess_args, handler=None, new_env=None):
    console_debug("subprocess", subprocess_args)
    # Start subprocess
    # bufsize = 1 means output is line buffered
    # universal_newlines = True is required for line buffering
    process = (
        subprocess.Popen(
            subprocess_args,
            bufsize=1,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
        )
        if new_env == None
        else subprocess.Popen(
            subprocess_args,
            bufsize=1,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            env=new_env,
        )
    )
    # Create callback function for process output
    buf = io.StringIO()

    def handle_output(stream, mask):
        # Because the process' output is line buffered, there's only ever one
        # line to read when this function is called
        line = stream.readline()
        buf.write(line)
        console_warning(line.rstrip())

    if handler == None:
        handler = handle_output


    # Register callback for an "available for read" event from subprocess' stdout stream
    selector = selectors.DefaultSelector()
    selector.register(process.stdout, selectors.EVENT_READ, handler)

    # Loop until subprocess is terminated
    while process.poll() is None:
        # Wait for events and handle them with their registered callbacks
        events = selector.select()
        for key, mask in events:
            callback = key.data
            callback(key.fileobj, mask)

    # Get process return code
    remaining = process.stdout.read()
    if remaining:
        buf.write(remaining)
        for line in remaining.splitlines():
            console_warning(line.strip())

triton_llvm = None
def get_install_path() -> tuple:
    """
    Load the install path from the config file. If the config file is not found, will return empty string
    Note runtime type and update global
    Returns:
        tuple: (str, str) - The install type and the path to the project directory
    """
    config_search_paths = [
        os.path.join(os.path.dirname(__file__), "../build/runtime_config.txt"),
        os.path.join(os.path.dirname(__file__), "runtime_config.txt"),
    ]
    install_dir = ""
    build_dir = ""
    global triton_llvm
    # Iterate over search paths for the config file, and load the paths into the program.
    # The runtime type (triton or hip) is also loaded globally to trigger the Triton configuration
    for path in config_search_paths:
        path = os.path.abspath(path)
        if os.path.exists(path):
            print(f"Found config file at {path}")
            with open(path, "r") as f:
                for line in f:
                    if line.startswith("build_dir="):
                        build_dir = line.strip().split("=")[1]
                    elif line.startswith("install_dir="):
                        install_dir = line.strip().split("=")[1]
                    elif line.startswith("triton_llvm="):
                        triton_llvm = line.strip().split("=")[1]
                    else:
                        print(f"Invalid line in {path}: {line}")
                        sys.exit(1)
            break

    if os.path.realpath(os.path.join(install_dir, "bin", "logDuration"))  == os.path.realpath(os.path.dirname(__file__)):
        return ("install", install_dir)
    else:
        return ("build", build_dir)

def get_default_cache_location():
    return str(Path.home()) + "/.triton/cache"

def get_rocm_path():
    tmp = shutil.which("rocminfo")
    nodes = tmp.split("/")
    if len(nodes) > 2:
        return "/".join(nodes[:len(nodes) - 2])

def get_omniprobe_home():
    tmp = os.path.dirname(__file__)
    return os.path.abspath(tmp)

def get_local_isa():
    local_isa = None
    output = []

    def handle_isa_output(stream, mask):
        # Because the process' output is line buffered, there's only ever one
        # line to read when this function is called
        line = stream.readline()
        output.append(line)

    capture_subprocess_output(["rocminfo"], handler=handle_isa_output, new_env=None)
    for line in output:
        for arch in ["gfx906", "gfx908", "gfx90a", "gfx940", "gfx941", "gfx942"]:
            if arch in line:
                return arch
    return None

install_path = get_install_path()
if install_path[0] == "install":
    base_llvm_pass_plugin = os.path.join(install_path[1])
    base_hsa_tools_lib = os.path.join(install_path[1], "lib", "logDuration")
else:
    base_llvm_pass_plugin = os.path.join(install_path[1], "external", "instrument-amdgpu-kernels-triton", "build")
    base_hsa_tools_lib = os.path.join(install_path[1])

#TODO: We need some way of communicating whether the target application is HIP or Triton source
# Hardcoding this for now
triton_config = {"TRITON_LOGGER_LEVEL": "3",
                 "TRITON_ALWAYS_COMPILE": "1",
                 "TRITON_DISABLE_LINE_INFO": "0",
                 "TRITON_HIP_LLD_PATH": f"{get_rocm_path()}/llvm/bin/ld.lld",
                 "LLVM_PASS_PLUGIN_PATH": os.path.join(base_llvm_pass_plugin, "lib", "libAMDGCNSubmitAddressMessages-triton.so")
                }

hip_config = {"LLVM_PASS_PLUGIN_PATH": os.path.join(base_llvm_pass_plugin, "lib", "libAMDGCNSubmitAddressMessages-rocm.so")}

config_path = os.path.dirname(__file__) + "/config"
rocm_path = get_rocm_path()

analytics_config = {}

op_run_env = {"LOGDUR_INSTRUMENTED": "false", "HSA_TOOLS_LIB": os.path.join(base_hsa_tools_lib, "liblogDuration64.so")}

def validate_triton_config():
    global triton_config
    if 'TRITON_HIP_LLD_PATH' not in triton_config or 'LLVM_PASS_PLUGIN_PATH' not in triton_config:
        print("You are missing some required configuration parameters in your triton environment. You need to specify all of the following environment variables:")
        print(f"\tTRITON_HIP_LLD_PATH (usually located whereever rocm is installed (e.g. {get_rocm_path()}/llvm/bin/ld.lld)")
        print(f"\tLLVM_PASS_PLUGIN_PATH (should be located {base_llvm_pass_plugin}")
        return False
    else:
        if not os.path.exists(triton_config['TRITON_HIP_LLD_PATH']):
            print(f"The file pointed to by TRITON_HIP_LLD_PATH ({triton_config['TRITON_HIP_LLD_PATH']}) is missing")
            return False
        if not os.path.exists(triton_config['LLVM_PASS_PLUGIN_PATH']):
            print(f"The file pointed to by LLVM_PASS_PLUGIN_PATH ({triton_config['LLVM_PASS_PLUGIN_PATH']}) is missing")
            return False
    return True

def validate_hip_config():
    global hip_config
    if 'LLVM_PASS_PLUGIN_PATH' not in hip_config:
        print("You are missing some required configuration parameters in your HIP environment. You need to specify all of the following environment variables:")
        print(f"\tLLVM_PASS_PLUGIN_PATH (should be located {base_llvm_pass_plugin}")
        return False
    else:
        if not os.path.exists(triton_config['LLVM_PASS_PLUGIN_PATH']):
            print(f"The file pointed to by LLVM_PASS_PLUGIN_PATH ({triton_config['LLVM_PASS_PLUGIN_PATH']}) is missing")
            return False
    return True

def setup_env(parms):
    env_dump = {}
    global op_run_env
    global triton_llvm
    env = os.environ
    if len(parms.log_location):
        if parms.log_location != "console":
            if not os.path.isdir(parms.log_location):
                env['LOGDUR_LOG_LOCATION'] = parms.log_location
                env_dump['LOGDUR_LOG_LOCATION'] = parms.log_location

            else:
                print(f"WARNING: log location {parms.log_location} either doesn't exist or it is a directory. Will log to the console.")
                parms.log_location = "console"
    else:
        env['LOGDUR_LOG_LOCATION'] = "console"
        env_dump['LOGDUR_LOG_LOCATION'] = "console"

    assume_triton = False
    if len(parms.cache_location):
        assume_triton = True
        if os.path.exists(parms.cache_location) and os.path.isdir(parms.cache_location):
            env['LOGDUR_KERNEL_CACHE'] = parms.cache_location
            env_dump['LOGDUR_KERNEL_CACHE'] = parms.cache_location
        elif not os.path.exists(parms.cache_location):
            try:
                os.makedirs(parms.cache_location)
                env['LOGDUR_KERNEL_CACHE'] = parms.cache_location
                env_dump['LOGDUR_KERNEL_CACHE'] = parms.cache_location
            except OSError as e:
                print(f"WARNING: Cache location {parms.cache_location} could not be created. Will use only instrumented kernels found in the application binary.")
                print(e)
        else:
            print(f"WARNING: Cache location {parms.cache_location} either doesn't exist, can't be created, or it isn't a directory. Will only use instrumented kernels found in the application binary.")

    if len(parms.dispatches):
        env['LOGDUR_DISPATCHES'] = parms.dispatches
        env_dump['LOGDUR_DISPATCHES'] = parms.dispatches

    if parms.instrumented == True:
        env['LOGDUR_INSTRUMENTED'] = "true"
        env_dump['LOGDUR_INSTRUMENTED'] = "true"
        if assume_triton:
            print("Triton cache location provided; assuming Triton run.")
            if validate_triton_config():
                for key in triton_config:
                    env[key] = triton_config[key]
                    env_dump[key] = triton_config[key]
            else:
                sys.exit(1)
        else:
            print("No Triton cache location provided; assuming HIP run.")
            if validate_hip_config():
                for key in hip_config:
                    env[key] = hip_config[key]
                    env_dump[key] = hip_config[key]
            else:
                sys.exit(1)

    if len(parms.kernels):
        if parms.instrumented == False:
            print("--kernels parameter is only used when running instrumented kernels. It will be ignored.")
        else:
            env['LOGDUR_FILTER'] = parms.kernels
            env_dump['LOGDUR_FILTER'] = parms.kernels

    env['HSA_TOOLS_LIB'] = op_run_env['HSA_TOOLS_LIB']
    env_dump['HSA_TOOLS_LIB'] = op_run_env['HSA_TOOLS_LIB']
    env['LOGDUR_HANDLERS'] = ','.join(parms.handlers)
    env_dump['LOGDUR_HANDLERS'] = ','.join(parms.handlers)
    env['LD_LIBRARY_PATH'] = ':'.join([f"{get_omniprobe_home()}/lib",env["LD_LIBRARY_PATH"]])
    env_dump['LD_LIBRARY_PATH'] = env['LD_LIBRARY_PATH']
    if parms.dump_env == True:
        dump_string = ""
        for key in env_dump:
            dump_string += f"{key}={env_dump[key]} "
        print(dump_string)
    return env


def load_config_files():
    global config_path
    global op_run_env
    global analytics_config
    files = os.listdir(config_path)
    for file in files:
        f = open(f"{config_path}/{file}", "r")
        txt = f.read()
        p = eval(txt)
        #Is it a general config file?
        if isinstance(p, dict):
            keys = p.keys();
            for key in keys:
                if key in op_run_env:
                    print(f"Duplicate configuration value for {key} in {config_path}/config/{file}")
                else:
                    op_run_env[key] = p[key]
        #If it's a list then this is a description of all the analytics that are available
        elif isinstance(p, list):
            for rec in p:
                if 'name' in rec and 'description' in rec and 'lib_name' in rec:
                    analytics_config[rec['name']] = rec
                else:
                    print("Invalid analytic config file. Each entry must contain a name, description, and lib_name")
                    sys.exit(1)



def add_general_group(parser):
    general_group = parser.add_argument_group("General omniprobe arguments")

    global analytics_config
    global install_path

    names = []
    for rec in analytics_config.keys():
        names.append(analytics_config[rec]['name'])

    general_group.add_argument (
        "-v",
        "--verbose",
        action="store_true",
        dest="verbose",
        required=False,
        default=False,
        help="\tVerbose output"
    )
    '''
    general_group.add_argument (
        "-t",
        "--type",
        type=str,
        metavar="",
        dest="type",
        required=False,
        default="memorytrace",
        help="\tSpecify the type of instrumentation to run"
    )
    '''

    general_group.add_argument (
        "-k",
        "--kernels",
        type=str,
        metavar="",
        dest="kernels",
        required=False,
        default="",
        help="\tKernel filters to define which kernels are instrumented. Valid ECMAScript regular expressions are supported. (cf. https://cplusplus.com/reference/regex/ECMAScript/)"
    )
    general_group.add_argument (
        "-i",
        "--instrumented",
        type=bool,
        action=argparse.BooleanOptionalAction,
        metavar="",
        dest="instrumented",
        required=False,
        default=False,
        help="\tRun instrumented kernels"
    )

    general_group.add_argument (
        "-e",
        "--env-dump",
        type=bool,
        action=argparse.BooleanOptionalAction,
        metavar="",
        dest="dump_env",
        required=False,
        default=False,
        help="\tDump all the environment variables for running liblogDuration64.so."
    )


    general_group.add_argument (
        "-d",
        "--dispatches",
        type=str,
        metavar="",
        dest="dispatches",
        required=False,
        default="all",
        help="\tThe dispatches for which to capture instrumentation output. This only applies when running with --instrumented.  Valid options: [all, random, 1]"
    )

    general_group.add_argument (
        "-c",
        "--cache-location",
        type=str,
        metavar="",
        dest="cache_location",
        required=False,
        default="",
        help="\tThe location of the file system cache for instrumented kernels. For Triton this is typically found at $HOME/.triton/cache"
    )

    general_group.add_argument (
        "-l",
        "--log-location",
        type=str,
        metavar="",
        dest="log_location",
        required=False,
        default="console",
        help="\tThe location where all of your data should be logged. By default it will be to the console."
    )

    default_handlers = [os.path.join(install_path[1], "lib", "libdefaultMessageHandlers64.so")] if install_path[0] == "install" else [os.path.join(install_path[1], "libdefaultMessageHandlers64.so")]
    general_group.add_argument (
        "-a",
        "--analyzers",
        type=str,
        metavar="",
        dest="handlers",
        required=False,
        nargs='+',
        default=default_handlers,
        help=f"\tThe analyzer(s) to use for processing data being streamed from instrumented kernels. \n\tValid values are {names} or a reference to any shared library that implements an omniprobe message handler.\n"
    )

    general_group.add_argument(
        "remaining",
        metavar="-- [ ...]",
        default=None,
        nargs=argparse.REMAINDER,
        help="\tProvide command for instrumenting after a double dash.",
    )
    return

def parse_args():
    parser = argparse.ArgumentParser(description = "Command-line interface for running intra-kernel analytics on AMD Instinct GPUs",
        prog="omniprobe",
        formatter_class = lambda prog: argparse.RawTextHelpFormatter(
                prog, max_help_position=30
            ),
            usage="omniprobe [options] -- application"
           )
    parser._optionals.title = "Help"

    prog="omniprobe",
    allow_abbrev=False,
    formatter_class=lambda prog: argparse.RawTextHelpFormatter(prog, max_help_position=40)

    add_general_group(parser)
    parms = parser.parse_args()
    return parms


def main():
    print("\nOmniprobe is developed by Advanced Micro Devices, Research and Advanced Development")
    print("Copyright (c) 2024 Advanced Micro Devices. All rights reserved.\n")
    logging.basicConfig(format="%(message)s", level=logging.INFO)
    global analytics_config
    load_config_files()
    parms  = parse_args()
    handlers = []
    for h in parms.handlers:
        if not h.endswith(".so"):
            if h in analytics_config:
                handlers.append(analytics_config[h]['lib_name'])
            else:
                print(f"{h} is not a valid analyzer. Ignoring.")
        else:
            handlers.append(h)
    parms.handlers = handlers
    if len(parms.remaining) != 0 and not parms.dump_env == True:
        capture_subprocess_output(parms.remaining[1:], new_env=setup_env(parms))
    elif parms.dump_env == True:
        setup_env(parms)


if __name__ == "__main__":
    main()
