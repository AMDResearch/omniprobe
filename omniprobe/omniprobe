#!/usr/bin/env python3

import argparse
import os
import sys
import io
import selectors
import shutil
import glob
import subprocess
import logging
from pathlib import Path

#LOGDUR_INSTRUMENTED
#LOGDUR_KERNEL_CACHE
#HSA_TOOLS_LIB
#TRITON_LOGGER_LEVEL=3
#TRITON_HIP_LLD_PATH=${ROCM_HOME}/llvm/bin/ld.lld
#TRITON_ALWAYS_COMPILE=1
#TRITON_DISABLE_LINE_INFO=0
#AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE=[some .bc file used by llvm plugin]
#LLVM_PASS_PLUGIN=[location of plugin.so]


def get_default_cache_location():
    return str(Path.home()) + "/.triton/cache"

def get_rocm_path():
    tmp = shutil.which("rocminfo")
    nodes = tmp.split("/")
    if len(nodes) > 2:
        return "/".join(nodes[:len(nodes) - 2])

def get_omniprobe_home():
    tmp = os.path.dirname(__file__)
    nodes = tmp.split("/")
    if nodes[len(nodes) - 2] == '.':
        tmp = "/".join(nodes[len(nodes) - 2])
    return tmp

triton_config = {"TRITON_LOGGER_LEVEL": "3", 
                 "TRITON_ALWAYS_COMPILE": "1", 
                 "TRITON_DISABLE_LINE_INFO": "0",
                 "TRITON_HIP_LLD_PATH": f"{get_rocm_path()}/llvm/bin/ld.lld",
                 "AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE": f"{get_omniprobe_home()}/triton/MemTraceInstrumentationKernel-hip-amdgcn-amd-amdhsa-gfx90a.bc",
                 "LLVM_PASS_PLUGIN": f"{get_omniprobe_home()}/triton/libAMDGCNMemTrace.so"
                 }
config_path = os.path.dirname(__file__) + "/config"
rocm_path = get_rocm_path()

op_run_env = {"LOGDUR_INSTRUMENTED": "false", "HSA_TOOLS_LIB": f"{os.path.dirname(__file__)}/lib/liblogDuration64.so"}

def validate_triton_config():
    global triton_config
    if 'TRITON_HIP_LLD_PATH' not in triton_config or 'AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE' not in triton_config or 'LLVM_PASS_PLUGIN' not in triton_config:
        print("You are missing some required configuration parameters in your triton environment. You need to specify all of the following environment variables:")
        print(f"\tTRITON_HIP_LLD_PATH (usually located whereever rocm is installed (e.g. {get_rocm_path()}/llvm/bin/ld.lld)")
        print(f"\tAMDGCN_INSTRUMENTATION_FUNCTIONS_FILE (should be located in {get_omniprobe_home()}/triton.")
        print(f"\tLLVM_PASS_PLUGIN (should be located {get_omniprobe_home()}/triton.")
        return False
    else:
        if not os.path.exists(triton_config['TRITON_HIP_LLD_PATH']):
            print(f"The file pointed to by TRITON_HIP_LLD_PATH ({triton_config['TRITON_HIP_LLD_PATH']}) is missing")
            return False
        if not os.path.exists(triton_config['AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE']):
            print(f"The file pointed to by AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE ({triton_config['AMDGCN_INSTRUMENTATION_FUNCTIONS_FILE']}) is missing")
            print(f"\tIt should be in {get_omniprobe_home()}/triton")
            return False
        if not os.path.exists(triton_config['LLVM_PASS_PLUGIN']):
            print(f"The file pointed to by LLVM_PASS_PLUGIN ({triton_config['LLVM_PASS_PLUGIN']}) is missing")
            return False
    return True

def setup_env(parms):
    global op_run_env
    env = os.environ
    if len(parms.log_location):
        if parms.log_location != "console":
            if not os.path.isdir(parms.log_location):
                env['LOGDUR_LOG_LOCATION'] = parms.log_location
            else:
                print(f"WARNING: log location {parms.log_location} either doesn't exist or it is a directory. Will log to the console.")
                parms.log_location = "console"
    else:
        env['LOGDUR_LOG_LOCATION'] = "console"
    
    if len(parms.cache_location):
        if os.path.exists(parms.cache_location) and os.path.isdir(parms.cache_location):
            env['LOGDUR_KERNEL_CACHE'] = parms.cache_location
        else:
            print(f"WARNING: cache location {parms.cache_location} either doesn't exist or it isn't a directory. Will only use instrumented kernels found in the application binary.")
    
    if parms.instrumented == True:
        env['LOGDUR_INSTRUMENTED'] = "true"
        if validate_triton_config():
            for key in triton_config:
                env[key] = triton_config[key]
        else:
            sys.exit(1)

    if len(parms.kernels):
        if parms.instrumented == False:
            print("--kernels parameter is only used when running instrumented kernels. It will be ignored.")
        else:
            env['LOGDUR_FILTER'] = parms.kernels

    env['HSA_TOOLS_LIB'] = op_run_env['HSA_TOOLS_LIB']
    #print(env)
    return env


def load_config_files():
    global config_path
    global op_run_env
    files = os.listdir(config_path)
    for file in files:
        f = open(f"{config_path}/{file}", "r")
        txt = f.read()
        p = eval(txt)
        if isinstance(p, dict):
            keys = p.keys();
            for key in keys:
                if key in op_run_env:
                    print(f"Duplicate configuration value for {key} in {config_path}/config/{file}")
                else:
                    op_run_env[key] = p[key]

def console_log(*argv, indent_level=0):
    indent = ""
    if indent_level >= 1:
        indent = " " * 3 * indent_level + "|-> "  # spaces per indent level

    if len(argv) > 1:
        logging.info(indent + f"[{argv[0]}] {argv[1]}")
        logging.info(indent + f"[{argv[0]}] {argv[1]}")
    else:
        logging.info(indent + f"{argv[0]}")


def console_debug(*argv):
    if len(argv) > 1:
        logging.debug(f"[{argv[0]}] {argv[1]}")
    else:
        logging.debug(f"{argv[0]}")


def console_warning(*argv):
    if len(argv) > 1:
        for msg in argv:
            if len(msg) > 0:
                logging.info(f"[{msg}]")
        logging.warning(f"[{argv[0]}] {argv[1]}")
    elif len(argv[0]) > 0:
        logging.warning(f"{argv[0]}")


def capture_subprocess_output(subprocess_args, new_env=None):
    console_debug("subprocess", subprocess_args)
    # Start subprocess
    # bufsize = 1 means output is line buffered
    # universal_newlines = True is required for line buffering
    process = (
        subprocess.Popen(
            subprocess_args,
            bufsize=1,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
        )
        if new_env == None
        else subprocess.Popen(
            subprocess_args,
            bufsize=1,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            universal_newlines=True,
            env=new_env,
        )
    )
    # Create callback function for process output
    buf = io.StringIO()

    def handle_output(stream, mask):
        # Because the process' output is line buffered, there's only ever one
        # line to read when this function is called
        line = stream.readline()
        buf.write(line)
        console_warning(line.strip())

    # Register callback for an "available for read" event from subprocess' stdout stream
    selector = selectors.DefaultSelector()
    selector.register(process.stdout, selectors.EVENT_READ, handle_output)

    # Loop until subprocess is terminated
    while process.poll() is None:
        # Wait for events and handle them with their registered callbacks
        events = selector.select()
        for key, mask in events:
            callback = key.data
            callback(key.fileobj, mask)

    # Get process return code

def add_general_group(parser):
    general_group = parser.add_argument_group("General omniprobe arguments")

    general_group.add_argument (
        "-v",
        "--verbose",
        type=bool,
        metavar="",
        dest="verbose",
        required=False,
        default=False,
        help="\tVerbose output"
    )
    '''
    general_group.add_argument (
        "-t",
        "--type",
        type=str,
        metavar="",
        dest="type",
        required=False,
        default="memorytrace",
        help="\tSpecify the type of instrumentation to run"
    )
    '''
    
    general_group.add_argument (
        "-k",
        "--kernels",
        type=str,
        metavar="",
        dest="kernels",
        required=False,
        default="",
        help="\tKernel filters to define which kernels are instrumented"
    )
    general_group.add_argument (
        "-i",
        "--instrumented",
        type=bool,
        action=argparse.BooleanOptionalAction,
        metavar="",
        dest="instrumented",
        required=False,
        default=False,
        help="\tRun instrumented kernels"
    )
    
    general_group.add_argument (
        "-d",
        "--dispatches",
        type=str,
        metavar="",
        dest="dispatches",
        required=False,
        default="all",
        help="\tThe dispatches for which to capture instrumentation output. This only applies when running with --instrumented.  Valid options: [all, random, 1]"
    )
    
    general_group.add_argument (
        "-c",
        "--cache-location",
        type=str,
        metavar="",
        dest="cache_location",
        required=False,
        default="",
        help="\tThe location of the file system cache for instrumented kernels. For Triton this is typically found at $HOME/.triton/cache"
    )
    
    general_group.add_argument (
        "-l",
        "--log-location",
        type=str,
        metavar="",
        dest="log_location",
        required=False,
        default="console",
        help="\tThe location where all of your data should be logged. By default it will be to the console."
    )
    
    general_group.add_argument (
        "-a",
        "--analyzer",
        type=str,
        metavar="",
        dest="handler",
        required=False,
        default="default",
        help="\tYour custom analyzer for processing data being streamed from instrumented kernels. Can be a shared library reference or a python module"
    )
    
    general_group.add_argument(
        "remaining",
        metavar="-- [ ...]",
        default=None,
        nargs=argparse.REMAINDER,
        help="\tProvide command for instrumenting after a double dash.",
    )
    return

def parse_args():
    parser = argparse.ArgumentParser(description = "Command-line interface for running intra-kernel analytics on AMD Instinct GPUs",
        prog="omniprobe",
        formatter_class = lambda prog: argparse.RawTextHelpFormatter(
                prog, max_help_position=30
            ),
            usage="omniprobe [options] -- application"
           )
    parser._optionals.title = "Help"
    
    prog="omniprobe",
    allow_abbrev=False,
    formatter_class=lambda prog: argparse.RawTextHelpFormatter(prog, max_help_position=40)

    add_general_group(parser)
    parms = parser.parse_args()
    return parms

    
def main():
    print("\nOmniprobe is developed by Advanced Micro Devices, Research and Advanced Development")
    print("Copyright (c) 2024 Advanced Micro Devices. All rights reserved.\n")
    load_config_files()
    parms  = parse_args()
    global op_run_env
    if len(parms.remaining) != 0:
        print(f"Trying to run {parms.remaining[1:]}")
        capture_subprocess_output(parms.remaining[1:], setup_env(parms))
        

if __name__ == "__main__":
    main()
