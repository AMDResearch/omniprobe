# logduration

[![Ubuntu 22.04 (w/ ROCm LLVM)](https://github.com/AARInternal/logduration/actions/workflows/ubuntu-jammy-rocm.yml/badge.svg)](https://github.com/AARInternal/logduration/actions/workflows/ubuntu-jammy-rocm.yml)
[![Ubuntu 22.04 (w/ Triton LLVM)](https://github.com/AARInternal/logduration/actions/workflows/ubuntu-jammy-triton.yml/badge.svg)](https://github.com/AARInternal/logduration/actions/workflows/ubuntu-jammy-triton.yml)

logduration is a project that originally started simply to provide a quick and easy way to observe all kernel
durations within an application, without having to run the profiler and be saddled with all of the application
perturbation profiling involves (e.g. kernels are serialized). It's going to end up doing more than that though.

I've long had an interest in creating the capability to silently replace kernel objects in dispatch packets with
alternatives so that developers can experiment without having to rebuild entire applications. So I'm adding
the ability to logduration to point it at a kernel cache. What it wants is a directory containing any number of hsaco
files generated by the compiler. As the tool observes and logs kernel durations, which it pries out of
the dispatch completion_signal, if it finds a kernel in the kernel cache, with and identical name and parameter list,
it will silently replace the kernel the app dispatched with an equivalent kernel from the kernel cache.

Silently replacing kernels is a technique the Audacious Software team plans to use for its instrumented kernel functionality. 
But I suspect it will be really useful even just for doing comparative performance analysis while avoiding
the rebuilding of entire applications.
## Running
HSA_TOOLS_LIB=\<path to liblogdur64.so\> <your application here\>  

e.g. HSA_TOOLS_LIB=./build/liblogdur64.so ./src/test/quicktest
## Environment Variables
- LOGDUR_LOG_LOCATION
  - console
  - file name
  - /dev/null
- LOGDUR_KERNEL_CACHE
  - The kernel cache should be pointed at a directory containing .hsaco files which represented alternative candidates
  to the kernels being dispatched by the application. If running "instrumented kernels" (see the next environment variable description), logDuration
  will look for an identically named kernel with the same parameter list and types, but with a single additional void * parameter (needed for the
  data streaming to the host from instrumented kernels.) If logDuration is not running in instrumented mode (e.g. LOGDUR_INSTRUMENTED = "false"),
  when the kernel cache is enabled it will look for kernels in the cache having identical names and parameters. This can be useful when wanting
  to compare different versions of the same kernel for overall duration.
- LOGDUR_INSTRUMENTED
  - Value can be either "true" or "false". If set to "true", the kernel cache will replace dispatched kernels with an instrumented alternative.
- LOGDUR_DISPATCHES=all
- LOGDUR_INSTRUMENTED=true
- LOGDUR_HANDLERS=\<Message Handler for processing messages from instrumented kernels.\> e.g. libLogMessages64.so
## omniprobe
```
Omniprobe is developed by Advanced Micro Devices, Research and Advanced Development
Copyright (c) 2024 Advanced Micro Devices. All rights reserved.

usage: omniprobe [options] -- application

Command-line interface for running intra-kernel analytics on AMD Instinct GPUs

Help:
  -h, --help                  show this help message and exit

General omniprobe arguments:
  -v , --verbose              	Verbose output
  -k , --kernels              	Kernel filters to define which kernels are instrumented. Valid ECMAScript regular
                                expressions are supported. (cf. https://cplusplus.com/reference/regex/ECMAScript/)
  -i, --instrumented, --no-instrumented
                              	Run instrumented kernels (default: False)
  -e, --env-dump, --no-env-dump
                              	Dump all the environment variables for running liblogDuration64.so.
                                (default: False)
  -d , --dispatches           	The dispatches for which to capture instrumentation output. This only applies when
                                running with --instrumented.  Valid options: [all, random, 1]
  -c , --cache-location       	The location of the file system cache for instrumented kernels. For Triton this is
                                typically found at $HOME/.triton/cache
  -l , --log-location         	The location where all of your data should be logged. By default it will be to the
                                console.
  -a  [ ...], --analyzers  [ ...]
                              	The analyzer(s) to use for processing data being streamed from instrumented kernels. 
                              	Valid values are ['MessageLogger', 'Heatmap', 'MemoryAnalysis'] or a reference to any
                                shared library that implements an omniprobe message handler.
  -- [ ...]                   	Provide command for instrumenting after a double dash.
```
## Building  
This project has several [dependencies](#dependencies) that are included as submodules. By default, logduration builds with ROCm instrumentation support.

Override the default ROCm LLVM search path via `ROCM_PATH`. To build with support for Triton instrumentation, we require you set `TRITON_LLVM`.

```shell
  git clone https://github.com/AARInternal/logduration.git
  cd logduration
  git submodule update --init --recursive
  mkdir build
  cd build
  cmake -DTRITON_LLVM=$HOME/.triton/llvm/llvm-a66376b0-ubuntu-x64 ..
  make
  # Optionally, install the program
  make install
```

> [!TIP]
> See [FAQ](#faq) for reccomended Triton installation procedure.

## Dependencies
logDuration is now dependent on two other libraries for building, and a third library if you want to use logDuration as part of omniprobe.
### [kerneldb](https://github.com/AARInternal/kerneldb.git)
> kernelDB provides support for query kernel codes from HSA code objects. This can be an important capability for processing instrumented kernel output.
> The omniprobe memory efficiency analyzer relies on this because sometimes code optimizations are made downstream in the compiler from where instrumentation
> occurred. And proper analysis of, say, memory traces requires understanding how the code may have been optimized (e.g. ganging together individual loads into dwordx4)

### [dh_comms](https://github.com/AARInternal/dh_comms.git)
> dh_comms provides buffered I/O functionality for propagating messages from instrumented kernels to host code for consuming and analyzing messages from instrumented code at runtime.
> Because logDuration can run in either instrumented or non-instrumented mode, dh_comms functionality needs to be built into logDuration.
> 
### [instrument-amdgpu-kernels](https://github.com/CRobeck/instrument-amdgpu-kernels.git)
> Unlike either dh_comms or kerneldb, instrument-amdgpu-kernel does not get linked into logDuration, but the llvm plugins provided by this library do the instrumentation of GPU kernels
> that logDuration relies on when running in instrumented mode. For now, when you build instrument-amdgpu-kernels for logDuration, you need to use the dh_comms_submit_address branch.

## FAQ

### How do you recommend I install Triton?
To build with Triton instrumentation support, we require you provide the path to Triton's LLVM install (`TRITON_LLVM`). We recommend using a virtual Python environment to avoid clobbering your other packages.

1. Follow Triton's ["Install from source"](https://github.com/triton-lang/triton?tab=readme-ov-file#install-from-source) instructions. 
2. Install PyTorch using their ROCm specific install instructions in their ["Getting started"](https://pytorch.org/get-started/locally/) guide.